{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["\u003ca href=\"https://colab.research.google.com/github/Plogeur/HAI923/blob/master/Notebook_GAN.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"]},{"cell_type":"markdown","metadata":{"id":"_VQSC8frX5Ao"},"source":["# Installation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"V6MbWkf0b-v4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.23.5)\n","Requirement already satisfied: pillow\u003c10.1.0,\u003e=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n","Collecting git+https://github.com/tensorflow/docs\n","  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-g2u63iau\n","  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-g2u63iau\n","  Resolved https://github.com/tensorflow/docs to commit 70174a87eb9c39b6f71d948801e140e9436e66e8\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting astor (from tensorflow-docs==2023.12.6.69331)\n","  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.12.6.69331) (1.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.12.6.69331) (3.1.2)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.12.6.69331) (5.9.2)\n","Requirement already satisfied: protobuf\u003e=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.12.6.69331) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.12.6.69331) (6.0.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etensorflow-docs==2023.12.6.69331) (2.1.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==2023.12.6.69331) (2.19.0)\n","Requirement already satisfied: jsonschema\u003e=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==2023.12.6.69331) (4.19.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==2023.12.6.69331) (5.5.0)\n","Requirement already satisfied: traitlets\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==2023.12.6.69331) (5.7.1)\n","Requirement already satisfied: attrs\u003e=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003etensorflow-docs==2023.12.6.69331) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003etensorflow-docs==2023.12.6.69331) (2023.11.2)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003etensorflow-docs==2023.12.6.69331) (0.32.0)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003etensorflow-docs==2023.12.6.69331) (0.13.2)\n","Requirement already satisfied: platformdirs\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core-\u003enbformat-\u003etensorflow-docs==2023.12.6.69331) (4.1.0)\n","Building wheels for collected packages: tensorflow-docs\n","  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-docs: filename=tensorflow_docs-2023.12.6.69331-py3-none-any.whl size=181263 sha256=3d665814a035f12e36453816629dfc727ead311f19968aa877204c4c9c1657f4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kskbylie/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n","Successfully built tensorflow-docs\n","Installing collected packages: astor, tensorflow-docs\n","Successfully installed astor-0.8.1 tensorflow-docs-2023.12.6.69331\n"]}],"source":["# To generate GIFs\n","!pip install imageio\n","!pip install git+https://github.com/tensorflow/docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZw2C6r8YJWW"},"outputs":[],"source":["import os\n","import random\n","import shutil\n","import keras\n","import imageio\n","import glob\n","import pathlib\n","import sys\n","import cv2\n","import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","from numpy import mean\n","from numpy import std\n","from keras import backend as K\n","from IPython import display\n","import matplotlib.cm as cm\n","import tensorflow as tf\n","from numpy import ones, zeros\n","from keras import metrics\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers\n","from numpy.random import randint\n","from tensorflow.keras.regularizers import L1L2\n","import tensorflow_docs.vis.embed as embed\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.saving import load_model\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.optimizers import Adam, Adamax, Lion\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from keras.layers import Input, Activation, Dropout, Dense, GlobalAveragePooling2D, Reshape, Flatten, Rescaling, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, LeakyReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18131,"status":"ok","timestamp":1702543613166,"user":{"displayName":"Dorine Fontaine","userId":"10440405550238291417"},"user_tz":-60},"id":"7c2nI_bUG0lo","outputId":"fc5aba07-8140-4f48-8578-60aff5fcfb9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive/\n","[Errno 2] No such file or directory: 'gdrive/MyDrive/Colab_Notebooks/'\n","/content\n","mkdir: cannot create directory ‘Résultats/GAN’: No such file or directory\n","mkdir: cannot create directory ‘Résultats/checkpoint’: No such file or directory\n"]}],"source":["# GLOBAL VARIABLE\n","IMG_SIZE = 124\n","BATCH_SIZE = 4\n","CHANEL = 3\n","IMG_SHAPE=(IMG_SIZE, IMG_SIZE, CHANEL)\n","EPOCHS = 1000\n","VERBOSE = 1\n","COLUMNS = 25\n","SEED = 123\n","PATH_DIR = \"/content/gdrive/MyDrive/Colab_Notebooks/\"\n","POLICE_SIZE = 18 # Taille de la police pour les plot\n","plt.rcParams.update({'font.size': POLICE_SIZE})\n","\n","# SET SEED\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/MyDrive/Colab_Notebooks/\n","path = %pwd\n","%mkdir Résultats/GAN\n","%mkdir Résultats/checkpoint"]},{"cell_type":"markdown","metadata":{"id":"5A9Q5uksoYR8"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"VMwscLS-SgPb"},"source":["## GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UU6BgI4IdiY3"},"outputs":[],"source":["def create_generator(latent_dim=100):\n","  model = Sequential()\n","    # 1/4 de l'image (7x7) * nombre d'images possibles\n","  #n_nodes = 124 * 31 * 31\n","  n_nodes = 100 * 31 * 31\n","  model.add(Dense(n_nodes, input_dim=latent_dim))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.2))\n","  #model.add(Reshape((31, 31, 124)))\n","  model.add(Reshape((31, 31, 100)))\n","  # upsample to 14x14\n","  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.2))\n","  # upsample to 28x28\n","  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Conv2D(3, (7,7), activation='sigmoid', padding='same'))\n","  opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_xIV4Ced-EA"},"outputs":[],"source":["def create_discriminator():\n","  model = Sequential()\n","  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=[124,124,3]))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Dropout(0.3))\n","  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Dropout(0.3))\n","  model.add(Flatten())\n","  model.add(Dense(1, activation='sigmoid'))\n","  opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzmkF8YvGGHp"},"outputs":[],"source":["def create_training_data(path_data, list_classes, gray=False):\n","  training_data=[]\n","  for classes in list_classes:\n","    path=os.path.join(path_data, classes)\n","    class_num=list_classes.index(classes)\n","    for img in os.listdir(path):\n","      try :\n","        if gray == False :\n","          img_array = cv2.imread(os.path.join(path,img), cv2.COLOR_BGR2RGB)\n","          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n","        else :\n","          img_array = cv2.imread(os.path.join(path,img), cv2.COLOR_BGR2GRAY)\n","          equ = cv2.equalizeHist(new_array)\n","          new_array = np.hstack((new_array,equ))\n","        training_data.append([new_array, class_num])\n","      except Exception as e:\n","        pass\n","  return training_data\n","\n","def create_X_y(path_data, list_classes, gray=False, onehot=False):\n","      training_data=create_training_data(path_data, list_classes, gray)\n","      random.shuffle(training_data)\n","      X=[]\n","      y=[]\n","      for features, label in training_data:\n","        X.append(features)\n","        y.append(label)\n","      if gray == False :\n","        X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 3)\n","      else :\n","        X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n","      if onehot == False :\n","        y=np.array(y, dtype=np.float32)\n","      return X,y\n","\n","# Chargement et normalisation des données\n","def load_data(my_path,animal):\n","  my_classes=[animal]\n","  X,y=create_X_y(my_path,my_classes)\n","  # Surtout ne pas oublier de normaliser les données avec :\n","  X=X.astype('float32')\n","  X=X/255.0\n","  return X\n","\n","# Creation d'un jeu de données de vraies images\n","# les vraies images sont labélisées avec 1\n","def generate_real_samples(dataset, nb_images):\n","  # tirage aléatoire\n","  ix = randint(0, dataset.shape[0], nb_images)\n","  #serie = random.sample(range(0, dataset.shape[0]), nb_images)\n","  # sélection des images\n","  X = dataset[ix]\n","  # mettre 1 comme label de classe\n","  y = ones((nb_images, 1))\n","  return X, y\n","\n","# Création d'un faux jeu de données\n","# elles seront labélisées avec 0\n","def generate_fake_samples(nb_images):\n","  X = np.random.rand(IMG_SIZE * IMG_SIZE * 3 * nb_images)\n","  # reshape en images grises\n","  X = X.reshape((nb_images, IMG_SIZE, IMG_SIZE, 3))\n","  # mettre 0 comme label de classe\n","  y = zeros((nb_images, 1))\n","  return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzDCJxGGGKcw"},"outputs":[],"source":["# train the discriminator model\n","def train_discriminator(model, dataset, epochs=100, batchsize=20):\n","  # on constitue un jeu de données de batchsize/2 images réelles et images fausses\n","\thalf_batch = int(batchsize / 2)\n","\t# boucler sur les epochs\n","\tfor i in range(epochs):\n","\t\t# sélection d'images réelles\n","\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t# mettre à jour le discriminateur avec les images réelles\n","\t\t_, real_acc = model.train_on_batch(X_real, y_real)\n","\t\t# generation de fausses images\n","\t\tX_fake, y_fake = generate_fake_samples(half_batch)\n","\t\t# mise à jour du discriminateur avec de fausses images\n","\t\t_, fake_acc = model.train_on_batch(X_fake, y_fake)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"boRjKhueGLuZ"},"outputs":[],"source":["#@tf.function # This annotation causes the function to be \"compiled\"\n","def create_gan(generator_model, discriminator_model):\n","  # mettre les poids du discriminateur non entrable\n","  discriminator_model.trainable = False\n","  # création d'un seul modele qui regroupe generateur et discriminateur\n","  model = Sequential()\n","  # ajout du générateur\n","  model.add(generator_model)\n","  # ajout du discriminateur\n","  model.add(discriminator_model)\n","  opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","  model.compile(loss='binary_crossentropy', optimizer=opt)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWw1nXmCGNhQ"},"outputs":[],"source":["def generate_latent_points(latent_dim, nb_images):\n","  X_input = np.random.randn(latent_dim * nb_images)\n","  X_input = X_input.reshape(nb_images, latent_dim)\n","  return X_input\n","\n","def generate_fake_samples_for_generator(generator_model, latent_dim, nb_images):\n","  # generation des points\n","  X_input = generate_latent_points(latent_dim,nb_images)\n","  # prediction de la sortie du générateur\n","  X = generator_model.predict(X_input, verbose=0)\n","  # A ce niveau on considère que les images sont fausses\n","  # donc on met 0 comme label.\n","  y = zeros((nb_images, 1))\n","  return X, y\n","\n","def evaluate_model(dataset, epoch, generator_model, discriminator_model, latent_dim, nb_images=100, save_model=False):\n","  # récupération de vraies images pour le discriminateur\n","  X_real, y_real = generate_real_samples(dataset, nb_images)\n","  # Evaluation de l'accuracy pour le discriminateur\n","  _, acc_real = discriminator_model.evaluate(X_real, y_real, verbose=0)\n","\n","  # génération de fausses images pour le générateur et donc le gan\n","  X_fake, y_fake = generate_fake_samples_for_generator(generator_model, latent_dim, nb_images)\n","  # Evaluation du discriminateur avec des fausses images\n","  _, acc_fake = discriminator_model.evaluate(X_fake, y_fake, verbose=0)\n","\n","  # Save model each 100 epochs\n","  if save_model==True and epoch % 100 == 0 :\n","    # sauvegarde du generateur pour un autre usage\n","    print('save checkpoint')\n","    filename = '/content/gdrive/MyDrive/Colab Notebooks/Résultats/checkpoint/generator_model_GAN%03d.h5' % (epoch)\n","    generator_model.save(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5bVd0dbGPZK"},"outputs":[],"source":["def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=25):\n","  # Pour déterminer combien il y aura de batchs analysés à chaque epoch\n","  batch_per_epoch = int(dataset.shape[0] / n_batch)\n","  half_batch = int(n_batch / 2)\n","\t# manually enumerate epochs\n","  for epoch in range(1, n_epochs) :\n","\t\t# enumerate batches over the training set\n","    print(\"epoch n°\", epoch)\n","    for batch in range(batch_per_epoch) :\n","\t\t\t  # get randomly selected 'real' samples\n","        X_real, y_real = generate_real_samples(dataset, half_batch)\n","        # update discriminator model weights\n","        d_loss1, _ = d_model.train_on_batch(X_real, y_real, reset_metrics=False)\n","        # generate 'fake' examples\n","        X_fake, y_fake = generate_fake_samples_for_generator(g_model, latent_dim, half_batch)\n","        # update discriminator model weights\n","        d_loss2, _ = d_model.train_on_batch(X_fake, y_fake, reset_metrics=False)\n","        # prepare points in latent space as input for the generator\n","        X_gan = generate_latent_points(latent_dim, n_batch)\n","        # create inverted labels for the fake samples\n","        y_gan = ones((n_batch, 1))\n","        # update the generator via the discriminator's error\n","        g_loss = gan_model.train_on_batch(X_gan, y_gan, reset_metrics=False)\n","\n","    if epoch % 10 == 0 :\n","      # Produce images for the GIF\n","      display.clear_output(wait=True)\n","\n","      evaluate_model(dataset, epoch, generator_model, discriminator_model, latent_dim, 100, True)\n","      latent_dim=100\n","      COLUMNS = 9\n","      plt.figure(figsize=(5,5))\n","\n","      # Add an epoch counter to the top middle of the plot\n","      plt.text(0.5, 0.95, f'Epoch: {epoch}', horizontalalignment='center', verticalalignment='center',\n","                transform=plt.gca().transAxes, fontsize=10, color='white')\n","\n","      for image in range(COLUMNS):\n","        plt.subplot(3,3,image+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        noise=tf.random.normal([1,latent_dim])\n","        plt.imshow((generator_model.predict(noise, verbose=0)[0]+1)/2)\n","      print(epoch)\n","      plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/Résultats/GAN/image_at_epoch_{:04d}.png'.format(epoch), bbox_inches='tight')\n","      plt.show()"]},{"cell_type":"markdown","metadata":{"id":"xWwF8YruQlBY"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCmYdZQW7nmg"},"outputs":[],"source":["#S'il y a un model enregistré :\n","#generator_model = load_model('/content/gdrive/MyDrive/generator_model_GAN400.h5')\n","\n","#Sinon création du générateur\n","generator_model = create_generator()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-HWkc2IjEr7"},"outputs":[],"source":["#!wget https://www.lirmm.fr/~poncelet/Ressources/Tiger-Fox-Elephant.zip\n","\n","#import zipfile\n","#with zipfile.ZipFile(\"Tiger-Fox-Elephant.zip\",\"r\") as zip_ref:\n","    #zip_ref.extractall(\"/content/gdrive/MyDrive/Colab Notebooks/Data_Project\")"]},{"cell_type":"markdown","metadata":{"id":"q4dTaymyfrKD"},"source":["ARCHI 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z0yHztOXwVh","outputId":"9d943101-d747-423e-ab94-55d76a437168"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch n° 1\n"]}],"source":["latent_dim=100\n","epochs=10000\n","batchsize=32\n","CHANEL=3\n","# Création du discriminateur\n","discriminator_model = create_discriminator()\n","\n","# Création du GAN\n","gan_model = create_gan(generator_model, discriminator_model)\n","# Chargement des données\n","dataset = load_data('/content/gdrive/MyDrive/Colab Notebooks/Data_Projet/Tiger-Fox-Elephant/', \"fox\")\n","\n","# train model\n","train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs, batchsize)"]},{"cell_type":"markdown","metadata":{"id":"nFylC6P1ghxp"},"source":["## GIF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beb0MHlggtLN"},"outputs":[],"source":["anim_file = 'Gan.gif'\n","\n","with imageio.get_writer(anim_file, mode='I') as writer:\n","  filenames = glob.glob('Résultats/GAN/image*.png')\n","  filenames = sorted(filenames)\n","  for filename in filenames:\n","    image = imageio.v2.imread(filename)\n","    writer.append_data(image)\n","  image = imageio.v2.imread(filename)\n","  writer.append_data(image)\n","\n","embed.embed_file(anim_file)\n","\n","%rm Résultats/GAN/*.png"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["_VQSC8frX5Ao"],"name":"","provenance":[{"file_id":"1pcyIKtBzsF4IVhhR4W14rcE-b0kX6vbX","timestamp":1702219313238}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}